{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoders for image compression, generation and denoising\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports library and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "#Import pytorch:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import glob\n",
    "def FileRead(file_path):\n",
    "    data = nib.load(file_path).get_fdata()\n",
    "    return data[:,:,:]\n",
    "def normalize(x):\n",
    "    x = (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "    return x\n",
    "def denormalize(x):\n",
    "    x = x* (np.max(x)-np.min(x))+np.min(x) \n",
    "    return x\n",
    "path='./data'\n",
    "listFiles = glob.glob('./data/*.nii')\n",
    "totalData = np.dstack([normalize(FileRead(file)) for file in listFiles])\n",
    "totalData = np.rollaxis(totalData, -1)\n",
    "totalData = np.expand_dims(totalData, axis=-1)\n",
    "X_train, X_test = train_test_split(totalData, test_size=0.1, random_state=42)\n",
    "X_train=torch.tensor( np.squeeze(X_train))\n",
    "X_test=torch.tensor( np.squeeze(X_test))\n",
    "print('shape X train : ', X_train.shape)\n",
    "print('shape X test : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderCNN(nn.Module):\n",
    "    def __init__(self, C, embedding_dim):\n",
    "        super(AutoEncoderCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, C, kernel_size = 5, stride = 1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(C, C, kernel_size = 5, stride = 2), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(C, C, kernel_size = 3, stride = 2), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(C, embedding_dim, kernel_size = 4, stride = 1)   \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embedding_dim, C, kernel_size = 4, stride = 1), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(C, C, kernel_size = 3, stride = 2, output_padding = 1),  \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(C, C, kernel_size = 5, stride = 2, output_padding = 1),  \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(C, 1, kernel_size = 5, stride = 1) \n",
    "        )  \n",
    "    def encode(self, x):\n",
    "        x = encoder(x)\n",
    "        return x\n",
    "            \n",
    "    def decode(self, x):\n",
    "        x = decoder(x)\n",
    "        return x\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x[:,None,:,:])\n",
    "        x = self.decoder(x)\n",
    "        x = x.reshape((x.shape[0],256,256))        \n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(losses,label='Training loss function'):\n",
    "    # Display loss evolution\n",
    "    fig, axes = plt.subplots(figsize=(8,6))\n",
    "    axes.plot(losses,'r-',lw=2,label=label)\n",
    "    axes.set_xlabel('N iterations',fontsize=18)\n",
    "    axes.set_ylabel('Loss',fontsize=18)\n",
    "    plt.legend(loc='upper right',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise level (Modify here)\n",
    "noise_scale = 0.1\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.normal(loc=0\n",
    "                         , scale=noise_scale, size=X_train.shape)\n",
    "X_train_noisy = X_train + noise\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.).type(torch.FloatTensor).float()\n",
    "print(type(X_train_noisy))\n",
    "noise = np.random.normal(loc=0, scale=noise_scale, size=X_test.shape)\n",
    "X_test_noisy = X_test + noise\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.).type(torch.FloatTensor).float()\n",
    "\n",
    "# Datasets building\n",
    "train_Set_Denoise = TensorDataset(X_train_noisy, X_train)# FILL HERE\n",
    "test_Set_Denoise = TensorDataset(X_test_noisy, X_test)# FILL HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Create the model\n",
    "denoiser = AutoEncoderCNN(C=16,embedding_dim=32)\n",
    "# Move your model to the device\n",
    "denoiser = denoiser.to(device)\n",
    "\n",
    "print(denoiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "N_epochs = 500\n",
    "batch_size = 8\n",
    "learning_rate = 0.0005\n",
    "loss_function = nn.MSELoss()# FILL HERE\n",
    "# Dataloader\n",
    "trainLoader = DataLoader(train_Set_Denoise, batch_size=batch_size,shuffle=True, num_workers=0)\n",
    "testLoader = DataLoader(test_Set_Denoise, batch_size=batch_size,shuffle=True, num_workers=0)\n",
    "\n",
    "# FilePath for saving the model\n",
    "model_path = 'model_weights.pth'\n",
    "losses_path = 'training_losses.pkl'\n",
    "use_pretrained = True\n",
    "\n",
    "optimizer = optim.Adam(denoiser.parameters(), lr=learning_rate)# FILL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, opt, n_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    losses = []  \n",
    "    i=0\n",
    "    for epoch in range(n_epochs):  # Loop over epochs\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for features, labels in data_loader:      \n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            prediction = model(features)\n",
    "            loss = loss_function(prediction, labels)\n",
    "            losses.append(loss.item())\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    \n",
    "                print('[Epoch : %d, iteration: %5d] loss: %.3f'%\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "            i+=1   \n",
    "\n",
    "    print('Training done')\n",
    "\n",
    "    # Save the model's state_dict and the losses\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    with open(losses_path, 'wb') as f:\n",
    "        pickle.dump(losses, f)\n",
    "    print('Model and losses saved')\n",
    "\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_path) and os.path.exists(losses_path) and use_pretrained:\n",
    "    print('Model and losses found')\n",
    "    if torch.cuda.is_available():\n",
    "        denoiser.load_state_dict(torch.load(model_path))\n",
    "        with open(losses_path, 'rb') as f:\n",
    "            losses = pickle.load(f)\n",
    "    else:\n",
    "        denoiser.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
    "        with open(losses_path, 'rb') as f:\n",
    "            losses = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    print('Training model')\n",
    "    losses = train(denoiser, trainLoader, optimizer, N_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display loss:\n",
    "display(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move your model to the device\n",
    "denoiser = denoiser.to(device)\n",
    "\n",
    "# Compute and display example reconstructed test on the training dataset\n",
    "\n",
    "\n",
    "# Move your data to the device\n",
    "X_test_noisy = X_test_noisy.to(device)\n",
    "\n",
    "# Compute reconstructed images\n",
    "reconstructed_images = denoiser(X_test_noisy[:,:,:])\n",
    "\n",
    "# Print device and type of the data\n",
    "print(X_test_noisy[:n,:,:].device)\n",
    "\n",
    "# Convert the reconstructed images back to CPU and to a numpy array for display\n",
    "reconstructed_images = reconstructed_images.detach().cpu().numpy()\n",
    "for n in range(len(X_test_noisy)):\n",
    "    # Display:\n",
    "    plt.figure(figsize=(40,80))\n",
    "    ax = plt.subplot(1,2,1)\n",
    "    plt.imshow(X_test_noisy[n,:,:].cpu(),cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(1,2,2)\n",
    "    plt.imshow(reconstructed_images[n,:,:],cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
